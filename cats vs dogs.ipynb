{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":34,"outputs":[{"output_type":"stream","text":"/kaggle/input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n/kaggle/input/resnet50/imagenet_class_index.json\n/kaggle/input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n/kaggle/input/dogs-vs-cats-redux-kernels-edition/train.zip\n/kaggle/input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv\n/kaggle/input/dogs-vs-cats-redux-kernels-edition/test.zip\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import cv2\nfrom tqdm import tqdm          #Used for the purpose of showing iterations getting loaded in bar kind of form\nfrom random import shuffle\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.applications.resnet50 import preprocess_input\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.optimizers import Adam, RMSprop\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","execution_count":35,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"weight_loc = '../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'  \nWe'll not be using this path directly because it will cause some dimension error instead we will download weights of imagenet.\nHere is the explanation:\nhttps://stackoverflow.com/questions/60119041/failed-to-load-keras-resnet50-model-offline-using-weight-file"},{"metadata":{"trusted":true},"cell_type":"code","source":"path = '../input/dogs-vs-cats-redux-kernels-edition/'","execution_count":36,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_img_path = os.path.join(path,'train.zip')\ntest_img_path = os.path.join(path,'test.zip')","execution_count":37,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from zipfile import ZipFile\nwith ZipFile(train_img_path,'r') as zip:\n    zip.extractall('.')\n\nwith ZipFile(test_img_path,'r') as zip:\n    zip.extractall('.')","execution_count":38,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(os.listdir('../'))\nprint(os.listdir('../working'))","execution_count":39,"outputs":[{"output_type":"stream","text":"['lib', 'input', 'working']\n['__notebook_source__.ipynb', 'test', 'train']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"raw","source":"filename = os.listdir('../working/train')\nlabels = []\nfor file in filename:\n    category = file.split('.')[0]\n    if category == 'cat':\n        labels.append(0)\n    else:\n        labels.append(1)\n        \ndf = pd.DataFrame({'filename': filename, 'label': labels})\ndf.head()"},{"metadata":{"trusted":true},"cell_type":"raw","source":"train_image_list = os.listdir(\"./train/\")[0:20000]\ntest_image_list = os.listdir(\"./test/\")"},{"metadata":{"trusted":true},"cell_type":"code","source":"#One hot encoding labels: dog as 1 and cat as 0\ndef label_image(img):\n    category = img.split('.')[-3]\n    if category == 'cat': return [1,0]\n    elif category == 'dog': return [0,1]","execution_count":40,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#this function takes the image data, directory in which data is stored, and boolean wheather it's training data or test data as arguments\ndef process_data(data, data_dir, isTrain=True):\n    data_df = []                                   \n    for img in tqdm(data):\n        path = os.path.join(data_dir,img)   #Assigning path to images by concatenating directory and images \n        if(isTrain):\n            label = label_image(img)        #Calling label_image to assign labels to image present in training directory\n        else:\n            label = img.split('.')[0]\n        img = cv2.imread(path,cv2.IMREAD_COLOR)\n        img = cv2.resize(img, (224,224))\n        data_df.append([np.array(img),np.array(label)])     #append image and labels as numpy array in data_df list\n    return data_df","execution_count":41,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"raw","source":"def show_img(data, isTest = False):\n    fig, ax = plt.subplots(nrows = 5, ncols = 5, figsize = (15,15))\n    for i,data in enumerate(data[:25]):        #enumerate helps in keeping track of count of iterations\n        img_data = data[0]\n        img_num = data[1]\n        label = np.argmax(img_num)             #to get maximum indices of an array\n        if label == 1:\n            str_label = 'dog'\n        elif label == 0:\n            str_label = 'cat'\n        if(isTest):\n            str_label = 'None'\n        \n        ax[i//5, i%5].imshow(img_data)\n        ax[i//5, i%5].axis('off')\n        ax[i//5, i%5].set_title(str_label)\n    plt.show()"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = process_data(os.listdir('./train/')[0:2000], './train/')       #we are slicing here for decreasing memory consumption\n#show_img(train)","execution_count":42,"outputs":[{"output_type":"stream","text":"100%|██████████| 2000/2000 [00:04<00:00, 431.19it/s]\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = process_data(os.listdir('./test')[0:2000], './test', False)\n#show_img(test, True)","execution_count":43,"outputs":[{"output_type":"stream","text":"100%|██████████| 2000/2000 [00:04<00:00, 432.62it/s]\n","name":"stderr"}]},{"metadata":{},"cell_type":"raw","source":"TRAIN_DIR = '../working/train/'\nTEST_DIR = '../working/test/'\ntrain_images_dogs_cats = [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR)] # use this for full dataset\ntest_images_dogs_cats = [TEST_DIR+i for i in os.listdir(TEST_DIR)]"},{"metadata":{},"cell_type":"raw","source":"def prepare_data(list_of_images):\n    \"\"\"\n    Returns two arrays: \n        x is an array of resized images\n        y is an array of labels\n    \"\"\"\n    x = [] # images as arrays\n    y = [] # labels\n    \n    for image in list_of_images:\n        x.append(cv2.resize(cv2.imread(image), (224,224), interpolation=cv2.INTER_CUBIC))\n    \n    for i in list_of_images:\n        if 'dog' in i:\n            y.append(1)\n        elif 'cat' in i:\n            y.append(0)           \n    return x, y"},{"metadata":{},"cell_type":"raw","source":"X, y = prepare_data(train_images_dogs_cats)"},{"metadata":{},"cell_type":"raw","source":"X = np.array([i[0] for i in train]).reshape(-1, 224, 224, 3)\ny = np.array([i[1] for i in train])\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 123)"},{"metadata":{"trusted":true},"cell_type":"code","source":"filename = os.listdir('../working/train')\nlabels = []\nfor file in filename:\n    category = file.split('.')[0]\n    if category == 'cat':\n        labels.append('cat')\n    else:\n        labels.append('dog')\n        \ndf = pd.DataFrame({'filename': filename, 'label': labels})\ndf.head()","execution_count":44,"outputs":[{"output_type":"execute_result","execution_count":44,"data":{"text/plain":"        filename label\n0   cat.5412.jpg   cat\n1   dog.1541.jpg   dog\n2   cat.4069.jpg   cat\n3  cat.12243.jpg   cat\n4  cat.12483.jpg   cat","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>cat.5412.jpg</td>\n      <td>cat</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>dog.1541.jpg</td>\n      <td>dog</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>cat.4069.jpg</td>\n      <td>cat</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>cat.12243.jpg</td>\n      <td>cat</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>cat.12483.jpg</td>\n      <td>cat</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df, valid_df = train_test_split(df, test_size = 0.2, stratify = df['label'], random_state = 123)\ntrain_df = train_df.reset_index(drop = True)\nvalid_df = valid_df.reset_index(drop = True)","execution_count":45,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(train_df))\nprint(len(valid_df))","execution_count":46,"outputs":[{"output_type":"stream","text":"20000\n5000\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen = ImageDataGenerator(preprocessing_function = preprocess_input)","execution_count":47,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_gen = datagen.flow_from_dataframe(train_df, directory = '../working/train', x_col = 'filename', y_col = 'label', target_size = (224,224), batch_size = 64)\nvalid_gen = datagen.flow_from_dataframe(valid_df, directory = '../working/train', x_col = 'filename', y_col = 'label', target_size = (224,224), batch_size = 64)","execution_count":48,"outputs":[{"output_type":"stream","text":"Found 20000 validated image filenames belonging to 2 classes.\nFound 5000 validated image filenames belonging to 2 classes.\n","name":"stdout"}]},{"metadata":{},"cell_type":"raw","source":"train_datagen = ImageDataGenerator(\n    rescale=1. / 255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True)\n\nval_datagen = ImageDataGenerator(\n    rescale=1. / 255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True)\n\ntrain_generator = train_datagen.flow(np.array(X_train), y_train, batch_size=64)\nvalidation_generator = val_datagen.flow(np.array(X_val), y_val, batch_size=64)"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(ResNet50(include_top = False, pooling = 'max', weights = 'imagenet'))\nmodel.add(Dense(1, activation = 'softmax'))\nmodel.layers[0].trainable = False","execution_count":49,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":50,"outputs":[{"output_type":"stream","text":"Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nresnet50 (Model)             (None, 2048)              23587712  \n_________________________________________________________________\ndense_1 (Dense)              (None, 1)                 2049      \n=================================================================\nTotal params: 23,589,761\nTrainable params: 2,049\nNon-trainable params: 23,587,712\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer = 'adam', metrics = ['accuracy'], loss = 'binary_crossentropy')","execution_count":51,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit_generator(train_gen, epochs = 10, validation_data = valid_gen)","execution_count":null,"outputs":[{"output_type":"stream","text":"Epoch 1/10\n313/313 [==============================] - 207s 660ms/step - loss: 7.6246 - accuracy: 0.5000 - val_loss: 7.6246 - val_accuracy: 0.5000\nEpoch 3/10\n211/313 [===================>..........] - ETA: 53s - loss: 7.6246 - accuracy: 0.5000","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}