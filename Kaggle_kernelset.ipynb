{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from keras.layers import Dense, Flatten, Dropout, Lambda, Input, Concatenate, concatenate\nfrom keras.models import Model\nfrom keras.applications import *\nfrom keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom keras.callbacks import ModelCheckpoint\nfrom keras import regularizers\nimport tensorflow as tf\nimport re\nAUTO = tf.data.experimental.AUTOTUNE\nfrom kaggle_datasets import KaggleDatasets","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"try: # detect TPUs\n  tpu = tf.distribute.cluster_resolver.TPUClusterResolver() # TPU detection\n  tf.config.experimental_connect_to_cluster(tpu)\n  tf.tpu.experimental.initialize_tpu_system(tpu)\n  strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept ValueError: # detect GPUs\n  strategy = tf.distribute.MirroredStrategy() # for GPU or multi-GPU machines\n  #strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n  #strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy() # for clusters of multi-GPU machines\n\nprint(\"Number of accelerators: \", strategy.num_replicas_in_sync)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls /kaggle/input/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"GCS_PATH = KaggleDatasets().get_gcs_path()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!gsutil ls $GCS_PATH","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = '../input/dogs-vs-cats-redux-kernels-edition/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_img_path = os.path.join(path,'train.zip')\ntest_img_path = os.path.join(path,'test.zip')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from zipfile import ZipFile\nwith ZipFile(train_img_path,'r') as zip:\n    zip.extractall('.')\n\nwith ZipFile(test_img_path,'r') as zip:\n    zip.extractall('.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(os.listdir('../'))\nprint(os.listdir('../working'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filenames = os.listdir(\"../working/train\")\nlabels = []\nfor file in filenames:\n    category = file.split('.')[0]\n    if category == 'cat':\n        labels.append('cat')\n    else:\n        labels.append('dog')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame({\n    'filename': filenames,\n    'label': labels\n})\ntrain_df, validation_df = train_test_split(df, test_size=0.1, random_state = 42)\ntrain_df = train_df.reset_index(drop=True)\nvalidation_df = validation_df.reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 64\ntrain_num = len(train_df)\nvalidation_num = len(validation_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def two_image_generator(generator, df, directory, batch_size,\n                        x_col = 'filename', y_col = None, model = None, shuffle = False,\n                        img_size1 = (224, 224), img_size2 = (299,299)):\n    gen1 = generator.flow_from_dataframe(\n        df,\n        directory,\n        x_col = x_col,\n        y_col = y_col,\n        target_size = img_size1,\n        class_mode = model,\n        batch_size = batch_size,\n        shuffle = shuffle,\n        seed = 1)\n    gen2 = generator.flow_from_dataframe(\n        df,\n        directory,\n        x_col = x_col,\n        y_col = y_col,\n        target_size = img_size2,\n        class_mode = model,\n        batch_size = batch_size,\n        shuffle = shuffle,\n        seed = 1)\n    \n    while True:\n        X1i = gen1.next()\n        X2i = gen2.next()\n        if y_col:\n            yield [X1i[0], X2i[0]], X1i[1]  #X1i[1] is the label\n        else:\n            yield [X1i, X2i]\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#add data_augmentation\ntrain_aug_datagen = ImageDataGenerator(\n    rotation_range = 20,\n    shear_range = 0.1,\n    zoom_range = 0.2,\n    width_shift_range = 0.1,\n    height_shift_range = 0.1,\n    horizontal_flip = True\n)\ntrain_generator = two_image_generator(train_aug_datagen, train_df, '../working/train',\n                                      batch_size = batch_size, y_col = 'label',\n                                      model = 'binary', shuffle = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation_datagen = ImageDataGenerator()\n\nvalidation_generator = two_image_generator(validation_datagen, validation_df,\n                                           '../working/train', batch_size = batch_size,\n                                           y_col = 'label',model = 'binary', shuffle = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_base_model(MODEL, img_size, lambda_fun = None):\n    inp = Input(shape = (img_size[0], img_size[1], 3))\n    x = inp\n    if lambda_fun:\n        x = Lambda(lambda_fun)(x)\n    \n    base_model = MODEL(input_tensor = x, weights = 'imagenet', include_top = False, pooling = 'avg')\n        \n    model = Model(inp, base_model.output)\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#define vgg + resnet50 + densenet\nmodel1 = create_base_model(vgg16.VGG16, (224, 224), vgg16.preprocess_input)\nmodel2 = create_base_model(resnet50.ResNet50, (224, 224), resnet50.preprocess_input)\nmodel3 = create_base_model(inception_v3.InceptionV3, (299, 299), inception_v3.preprocess_input)\nmodel1.trainable = False\nmodel2.trainable = True\nmodel3.trainable = False\n\ninpA = Input(shape = (224, 224, 3))\ninpB = Input(shape = (299, 299, 3))\nout1 = model1(inpA)\nout2 = model2(inpA)\nout3 = model3(inpB)\n\nx = Concatenate()([out1, out2, out3])                \nx = Dropout(0.6)(x)\nx = Dense(1, activation='sigmoid')(x)\nmultiple_pretained_model = Model([inpA, inpB], x)\n\nmultiple_pretained_model.compile(loss = 'binary_crossentropy',\n                          optimizer = 'rmsprop',\n                          metrics = ['accuracy'])\n\nmultiple_pretained_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpointer = ModelCheckpoint(filepath='dogcat.weights.best.hdf5', verbose=1, \n                               save_best_only=True, save_weights_only=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"multiple_pretained_model.fit_generator(\n    train_generator,\n    epochs = 5,\n    steps_per_epoch = train_num // batch_size,\n    validation_data = validation_generator,\n    validation_steps = validation_num // batch_size,\n    verbose = 1,\n    callbacks = [checkpointer]\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#write code for submission to .csv output here","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}